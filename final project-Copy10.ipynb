{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "745dedf4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64594716",
   "metadata": {},
   "source": [
    "data is saved on google drive(public)\\\n",
    "https://drive.google.com/drive/folders/1hbWqTjmpvFA-eba4LWN2NbFxJyQQKn3L?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b9b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorchvideo\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6563bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "import gensim, logging\n",
    "from gensim.models.word2vec import Word2Vec # the word2vec model gensim class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "87285dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorchvideo.transforms\n",
    "from torch import optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b97fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    RemoveKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    CenterCrop,\n",
    "    RandomCrop,\n",
    "    Resize,\n",
    "    RandomHorizontalFlip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def2b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'data/'\n",
    "names = []\n",
    "labels = []\n",
    "for dir in os.listdir(path):\n",
    "    label = dir.replace('.mp4','')\n",
    "    labels.append(label)\n",
    "    name = dir\n",
    "    names.append(name)\n",
    "dict = {'name':names,'messy label': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7e41c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>messy label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#BACK-[fingerspelled-version].mp4</td>\n",
       "      <td>#BACK-[fingerspelled-version]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#what-DO__DO-DO-[lexicalized-fingerspelling].mp4</td>\n",
       "      <td>#what-DO__DO-DO-[lexicalized-fingerspelling]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 dollars _ 10 dollars.mp4</td>\n",
       "      <td>10 dollars _ 10 dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25 cents _ 25-cents.mp4</td>\n",
       "      <td>25 cents _ 25-cents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 o clock version.mp4</td>\n",
       "      <td>3 o clock version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>ZIG-ZAG–(stripes on an object).mp4</td>\n",
       "      <td>ZIG-ZAG–(stripes on an object)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>ZIP-LIPS-[zip-your-lips].mp4</td>\n",
       "      <td>ZIP-LIPS-[zip-your-lips]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>ZIP-up-[general-version].mp4</td>\n",
       "      <td>ZIP-up-[general-version]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>ZIP-up-[jacket version].mp4</td>\n",
       "      <td>ZIP-up-[jacket version]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>ZIP-[Z-I-P].mp4</td>\n",
       "      <td>ZIP-[Z-I-P]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1696 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "0                    #BACK-[fingerspelled-version].mp4   \n",
       "1     #what-DO__DO-DO-[lexicalized-fingerspelling].mp4   \n",
       "2                          10 dollars _ 10 dollars.mp4   \n",
       "3                              25 cents _ 25-cents.mp4   \n",
       "4                                3 o clock version.mp4   \n",
       "...                                                ...   \n",
       "1691                ZIG-ZAG–(stripes on an object).mp4   \n",
       "1692                      ZIP-LIPS-[zip-your-lips].mp4   \n",
       "1693                      ZIP-up-[general-version].mp4   \n",
       "1694                       ZIP-up-[jacket version].mp4   \n",
       "1695                                   ZIP-[Z-I-P].mp4   \n",
       "\n",
       "                                       messy label  \n",
       "0                    #BACK-[fingerspelled-version]  \n",
       "1     #what-DO__DO-DO-[lexicalized-fingerspelling]  \n",
       "2                          10 dollars _ 10 dollars  \n",
       "3                              25 cents _ 25-cents  \n",
       "4                                3 o clock version  \n",
       "...                                            ...  \n",
       "1691                ZIG-ZAG–(stripes on an object)  \n",
       "1692                      ZIP-LIPS-[zip-your-lips]  \n",
       "1693                      ZIP-up-[general-version]  \n",
       "1694                       ZIP-up-[jacket version]  \n",
       "1695                                   ZIP-[Z-I-P]  \n",
       "\n",
       "[1696 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd85f1",
   "metadata": {},
   "source": [
    "## Clean the data label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e679d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data=[]\n",
    "counts =[]\n",
    "c_ = 0\n",
    "data = df['messy label']\n",
    "for row in data:\n",
    "    item =''\n",
    "    c_ +=1\n",
    "    for i in row:\n",
    "        if i =='_' or i=='[' or i =='(' or i ==',':\n",
    "            break\n",
    "        else:\n",
    "            item += i\n",
    "\n",
    "    if re.findall('\\w{2}-\\w{2}', item):\n",
    "        item = item.replace('-',' ')\n",
    "    redic ={'\\-\\w\\-':'-','\\-':'-','\\#':'#','\\@':'@','\\–':'–'}\n",
    "    for pattern in redic:\n",
    "        if re.findall(pattern, item):\n",
    "            item = item.replace(redic[pattern],'')\n",
    "\n",
    "    c_data.append(item.lower())\n",
    "    counts.append(c_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99e1a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#BACK-[fingerspelled-version].mp4</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#what-DO__DO-DO-[lexicalized-fingerspelling].mp4</td>\n",
       "      <td>what do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 dollars _ 10 dollars.mp4</td>\n",
       "      <td>10 dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25 cents _ 25-cents.mp4</td>\n",
       "      <td>25 cents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 o clock version.mp4</td>\n",
       "      <td>3 o clock version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>ZIG-ZAG–(stripes on an object).mp4</td>\n",
       "      <td>zig zag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>ZIP-LIPS-[zip-your-lips].mp4</td>\n",
       "      <td>zip lips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>ZIP-up-[general-version].mp4</td>\n",
       "      <td>zip up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>ZIP-up-[jacket version].mp4</td>\n",
       "      <td>zip up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>ZIP-[Z-I-P].mp4</td>\n",
       "      <td>zip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1696 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name              label\n",
       "0                    #BACK-[fingerspelled-version].mp4               back\n",
       "1     #what-DO__DO-DO-[lexicalized-fingerspelling].mp4            what do\n",
       "2                          10 dollars _ 10 dollars.mp4        10 dollars \n",
       "3                              25 cents _ 25-cents.mp4          25 cents \n",
       "4                                3 o clock version.mp4  3 o clock version\n",
       "...                                                ...                ...\n",
       "1691                ZIG-ZAG–(stripes on an object).mp4            zig zag\n",
       "1692                      ZIP-LIPS-[zip-your-lips].mp4          zip lips \n",
       "1693                      ZIP-up-[general-version].mp4            zip up \n",
       "1694                       ZIP-up-[jacket version].mp4            zip up \n",
       "1695                                   ZIP-[Z-I-P].mp4                zip\n",
       "\n",
       "[1696 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']=c_data\n",
    "df=df.drop('messy label', axis=1)\n",
    "df.to_csv('ASL Video Data.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "2c5e342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1691 & ZIG-ZAG–(stripes on an object).mp4 & zig zag \\\n",
      "1692 & ZIP-LIPS-[zip-your-lips].mp4 & zip lips  \\\n",
      "1693 & ZIP-up-[general-version].mp4 & zip up  \\\n",
      "1694 & ZIP-up-[jacket version].mp4 & zip up  \\\n",
      "1695 & ZIP-[Z-I-P].mp4 & zip \\\n"
     ]
    }
   ],
   "source": [
    "for i in range(1691,1696):\n",
    "    print(i,'&',str(df.iloc[i][0]),'&',str(df.iloc[i][1]),'\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a22f7b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 340\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
    "print('Test:',len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45e2e986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1084\n",
      "Valid: 272\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set = train_test_split(train_set, test_size=0.2, random_state=42, shuffle=True)\n",
    "print('Train:',len(train_set))\n",
    "print('Valid:',len(valid_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d15829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpath(dataset):\n",
    "    names = list(dataset['name'])\n",
    "    paths =[]\n",
    "    for i in range(len(names)):\n",
    "        name = names[i]\n",
    "        path = os.path.join('data/', name)\n",
    "        paths.append(path)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54ee7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath= getpath(train_set)\n",
    "validpath = getpath(valid_set)\n",
    "testpath = getpath(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c1c353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n"
     ]
    }
   ],
   "source": [
    "for i in trainpath:\n",
    "    source = i\n",
    "    destination = 'dataset/train/'\n",
    "    try:\n",
    "        shutil.copy(source, destination)\n",
    "        print(\"File copied successfully.\")\n",
    " \n",
    "    # If source and destination are same\n",
    "    except shutil.SameFileError:\n",
    "        print(\"Source and destination represents the same file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca0c619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n"
     ]
    }
   ],
   "source": [
    "for i in validpath:\n",
    "    source = i\n",
    "    destination = 'dataset/valid/'\n",
    "    try:\n",
    "        shutil.copy(source, destination)\n",
    "        print(\"File copied successfully.\")\n",
    " \n",
    "    # If source and destination are same\n",
    "    except shutil.SameFileError:\n",
    "        print(\"Source and destination represents the same file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00bc50e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n",
      "File copied successfully.\n"
     ]
    }
   ],
   "source": [
    "for i in testpath:\n",
    "    source = i\n",
    "    destination = 'dataset/test/'\n",
    "    try:\n",
    "        shutil.copy(source, destination)\n",
    "        print(\"File copied successfully.\")\n",
    " \n",
    "    # If source and destination are same\n",
    "    except shutil.SameFileError:\n",
    "        print(\"Source and destination represents the same file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9f4ef",
   "metadata": {},
   "source": [
    "## cleaned the data label into the colum 'label' and stored in the csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1da9f2",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "960448a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "listwords = []\n",
    "for i in df['label']:\n",
    "    listwords.append(i.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b1868f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = []\n",
    "for i in train_set['label']:\n",
    "    trainlist.append(i.split())\n",
    "trainm = Word2Vec(trainlist, min_count=1)\n",
    "trainwords =  list(trainm.wv.index_to_key)\n",
    "testlist =[]\n",
    "for i in test_set['label']:\n",
    "    testlist.append(i.split())\n",
    "testm = Word2Vec(testlist, min_count=1)\n",
    "testwords =  list(testm.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d5f98ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=1044, vector_size=100, alpha=0.025)\n",
      "first 100 words :  ['you', 'your', 'like', 'what', 'how', 'have', 'think', 'sign', 'go', 'many', 'to', 'name', 'class', 'want', 'live', 'up', 'version', 'eat', 'school', 'house', 'deaf', 'do', 'hair', 'before', 'suppose', 'this', 'favorite', 'look', 'city', 'here', 'people', 'me', 'in', 'finish', 'use', 'car', 'past', 'family', 'where', 'hearing', 'teacher', 'dad', 'take', 'learn', 'equal', 'much', 'prefer', 'self', 'year', 'cl', 'all', 'every', 'asl', 'with', 'book', 'night', 'can', 'shirt', 'feel', 'a', 'pizza', 'color', 'dog', 'doctor', 'why', 'movie', 'next', 'for', 'i', 'play', 'sister', 'children', 'law', 'work', 'need', 'earn', 'most', 'student', 'one', 'come', 'phone', 'money', 'backpack', 'tomorrow', 'or', 'yesterday', 'and', 'move', 'weekend', 'mom', 'sometimes', 'from', 'clothes', 'he', 'test', 'bedroom', 'college', 'wish', 'any', 'mind']\n",
      "[[ 6.1183586e-03 -1.9229189e-03  6.3761356e-03  1.5741596e-03\n",
      "   4.4058110e-03 -1.0529698e-02  7.6596886e-03  6.3749781e-04\n",
      "  -6.6751549e-03 -9.6479785e-03 -3.6448063e-04 -8.2272422e-03\n",
      "   6.1178082e-03  6.9829663e-03 -4.7369283e-03  3.0723724e-03\n",
      "   1.7498719e-03 -6.4560440e-03 -1.0401402e-03  4.5749187e-03\n",
      "   7.4507776e-03 -4.1937488e-04 -3.9254595e-03 -7.3871994e-03\n",
      "  -6.1813695e-03  8.5723065e-03  5.9626899e-03 -7.7796360e-03\n",
      "   6.2490952e-05 -9.5919520e-03  6.6951588e-03 -4.8512295e-03\n",
      "   1.8087848e-03 -8.5671637e-03  5.0191381e-03 -9.4902990e-03\n",
      "   6.0126963e-03  2.8847365e-03 -4.6599219e-03 -7.6866327e-03\n",
      "  -7.4399747e-03  9.4911113e-04  2.3894103e-03 -5.0978041e-03\n",
      "  -7.9538152e-03  8.7426286e-03 -2.7562187e-03 -5.7416838e-03\n",
      "  -6.9034933e-03  6.1722286e-04  9.3600340e-03  4.3708282e-03\n",
      "  -3.4207341e-03 -3.8521297e-03 -8.6153625e-03  6.8068523e-03\n",
      "  -9.1019552e-03 -3.8951777e-03 -3.6087721e-03 -1.9792749e-03\n",
      "  -9.1293817e-03 -1.2867578e-03 -6.2705977e-03 -1.5922177e-03\n",
      "  -7.4286057e-05  2.2838390e-03  3.9048118e-03 -5.0257002e-03\n",
      "   4.2115194e-03 -3.0017055e-03 -6.0860496e-03 -5.4036393e-03\n",
      "  -6.6659967e-03 -4.3921331e-03  7.2007040e-03  5.3918310e-03\n",
      "  -7.5658360e-03  2.4970633e-03  7.0151766e-03  9.1324765e-03\n",
      "  -1.2675185e-03  8.9662299e-03 -3.1394761e-03 -5.3266566e-03\n",
      "  -2.6245737e-03 -5.6449864e-03  4.9625537e-03  8.4332703e-03\n",
      "   9.1818720e-03 -7.1910694e-03 -8.6793285e-03  5.4550003e-03\n",
      "  -9.5512308e-03 -6.0465368e-03 -5.2478225e-03 -7.0187422e-03\n",
      "  -8.1456848e-04 -1.4769714e-03  9.9488767e-03  3.4908885e-03]\n",
      " [ 8.9014973e-03 -4.0048510e-03 -2.5772347e-04 -3.7210810e-03\n",
      "  -7.0784236e-03  2.0905500e-03 -2.5256546e-03  4.2213518e-03\n",
      "   3.2755111e-03  2.6929860e-03  7.8219986e-03  4.9592671e-03\n",
      "   9.5163677e-03 -6.9463491e-03 -9.8695876e-03 -6.1459513e-03\n",
      "   7.1110195e-03  1.8608810e-03  6.9448263e-03  4.7854534e-03\n",
      "  -5.7198098e-03  8.7061391e-04  8.0839973e-03 -7.7130124e-03\n",
      "  -4.2837826e-03 -4.3968288e-03 -1.7069837e-05  3.2813277e-05\n",
      "  -9.2700711e-03  8.0788871e-03 -7.4119591e-03 -1.7463694e-03\n",
      "   1.0011452e-02 -8.0965525e-03  5.3057084e-03  3.0100388e-03\n",
      "   1.2638749e-03 -6.6288435e-03  1.6941319e-03  6.3012736e-03\n",
      "  -3.6607927e-04  2.8593808e-03  3.7929553e-03  7.7622198e-03\n",
      "   7.5900168e-03 -9.3682315e-03  6.2900591e-03 -4.6005617e-03\n",
      "  -5.8031501e-03  1.3858227e-03  1.3465388e-03  9.3015574e-04\n",
      "  -5.5302992e-03 -8.2382131e-03  4.5768409e-03 -6.2615806e-03\n",
      "  -6.3160029e-03  8.4713560e-05 -8.2711102e-03 -2.9458667e-03\n",
      "   4.4360412e-03  9.9881869e-03 -4.9580950e-03  1.7554280e-03\n",
      "  -1.6443041e-03  6.1505837e-03  1.6539410e-03 -1.3624508e-03\n",
      "  -1.9378877e-03 -3.2380230e-03 -4.1881157e-03  8.9217583e-03\n",
      "  -7.1271393e-03  6.1274599e-03 -8.6667221e-03 -7.3827063e-03\n",
      "   2.2381165e-03  7.9850629e-03 -2.5749989e-03 -2.4882914e-03\n",
      "   7.1102055e-03  2.6804537e-03  5.3813527e-03  5.5104764e-03\n",
      "  -6.5649720e-03  2.0275987e-04 -2.6204390e-03 -4.0857471e-03\n",
      "  -2.2958643e-03  6.6420087e-03 -9.4723990e-03 -9.6717142e-03\n",
      "   6.0499427e-03  9.8894313e-03  1.2332882e-03 -1.5172394e-03\n",
      "  -6.5453658e-03  9.0015726e-03  3.9000988e-03 -2.8701618e-03]]\n"
     ]
    }
   ],
   "source": [
    "wordsmodel = Word2Vec(listwords, min_count=1)\n",
    "print(wordsmodel)\n",
    "words =  list(wordsmodel.wv.index_to_key)\n",
    "print(\"first 100 words : \",words[:100])\n",
    "# access vector for one word\n",
    "print(wordsmodel.wv['good', 'nice'])\n",
    "# save model\n",
    "wordsmodel.save('model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3dcd94",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2e8d7e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Per second: 29.97002997002997\n",
      "      Total Frames: 168.0\n",
      "      Height: 1080.0 \n",
      "      Width: 1920.0\n"
     ]
    }
   ],
   "source": [
    "# test with the first data path[0]\n",
    "cap = cv2.VideoCapture(trainpath[0])\n",
    "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "print(f\"\"\"Frame Per second: {video_fps }\n",
    "      Total Frames: {total_frames}\n",
    "      Height: {height} \n",
    "      Width: {width}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0a76260",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "            [\n",
    "            ApplyTransformToKey(\n",
    "              key=\"video\",\n",
    "              transform=Compose(\n",
    "                  [\n",
    "                    UniformTemporalSubsample(32),\n",
    "                    Lambda(lambda x: x / 255.0),\n",
    "                    Normalize((0.45, 0.45, 0.45), (0.225, 0.225, 0.225)),\n",
    "#                     RandomShortSideScale(min_size=256, max_size=320),\n",
    "                    ShortSideScale(size=397),\n",
    "                    Resize(256),CenterCrop(256),\n",
    "                    RandomHorizontalFlip(p=0.5),\n",
    "                  ]\n",
    "                ),\n",
    "              ),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "077f41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, label,  transform=None):\n",
    "        self.img_dir  = img_dir\n",
    "        self.label = label\n",
    "        self.transform  = transform\n",
    "        self.videos = os.listdir(img_dir)\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "    def __getitem__(self, index):\n",
    "        img_path    = os.path.join(self.img_dir, self.videos[index])\n",
    "        cap = cv2.VideoCapture(img_path)\n",
    "        video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        sampling_rate = 1\n",
    "        frames_per_second = video_fps\n",
    "        clip_duration = (total_frames * sampling_rate)/frames_per_second\n",
    "        start_sec = 0\n",
    "        end_sec = start_sec + clip_duration\n",
    "        \n",
    "        # convert the label str into np array with gensim library\n",
    "        # filling the caption into the video averagely into 32 frames\n",
    "        capt =self.label[index]\n",
    "        c = capt.split()\n",
    "        caption = []\n",
    "        for i in c:\n",
    "            try:\n",
    "                x = wordsmodel.wv[i]\n",
    "                x.reshape(1,100)\n",
    "                caption.append(x)\n",
    "            except:\n",
    "                x = wordsmodel.wv['None']\n",
    "                x.reshape(1,100)\n",
    "                caption.append(x)\n",
    "        caption  = np.array(caption)\n",
    "        num = len(caption)\n",
    "        mid = num//2\n",
    "        captions = np.repeat(caption, [32/num], axis =0)\n",
    "        while len(captions)<32:\n",
    "            captions = np.append(captions, caption[mid].reshape(1,100), axis =0)\n",
    "        \n",
    "        video = EncodedVideo.from_path(img_path)\n",
    "#         video_data = video\n",
    "        # Load the desired clip\n",
    "        video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(video_data)\n",
    "            video   = augmentations[\"video\"]\n",
    "#             audio  = augmentations[\"audio\"]\n",
    "        if video.shape==torch.Size([3, 32, 256, 256]) and captions.shape ==(32,100):\n",
    "            return video,  captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9d095c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE    = 32\n",
    "captionlist =list(train_set['label'])\n",
    "traindataset = SegmentationDataset(img_dir='dataset/train', label=captionlist,  transform=transform)\n",
    "train_loader = DataLoader( traindataset, batch_size=BATCH_SIZE, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "17ac9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "captionlist =list(valid_set['label'])\n",
    "validdataset = SegmentationDataset(img_dir='dataset/valid', label=captionlist,  transform=transform)\n",
    "valid_loader = DataLoader( validdataset, batch_size=BATCH_SIZE, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "58a09d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "captionlist =list(test_set['label'])\n",
    "testdataset = SegmentationDataset(img_dir='dataset/test', label=captionlist,  transform=transform)\n",
    "test_loader = DataLoader( testdataset, batch_size=BATCH_SIZE, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "aba7baf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 256, 256])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindataset[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "d1749e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindataset[1][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14cf0a",
   "metadata": {},
   "source": [
    "input datasize:\\\n",
    "    32 frames\\\n",
    "    image size [3,256,256]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3cc58f",
   "metadata": {},
   "source": [
    "## first CNN Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a769dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.conv3 = nn.Conv2d(20, 30, 5)\n",
    "        self.pool =  nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, i):\n",
    "#         x = i.view(-1, i.shape[2], i.shape[3], i.shape[4])\n",
    "        x = i.view(-1, i.shape[0], i.shape[3], i.shape[4])\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = nn.AvgPool2d(4)(x)\n",
    "        x = x.view(i.shape[0], i.shape[1], -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4f77f711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 15680])\n"
     ]
    }
   ],
   "source": [
    "net_cnn = CNN()\n",
    "# x = torch.rand(32,1,3,256,256)\n",
    "x = torch.rand(3, 10, 32, 256, 256)\n",
    "features = net_cnn(x)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62904e2",
   "metadata": {},
   "source": [
    "## LSTM Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "6efc5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(1470, 1000)\n",
    "        self.fc = nn.Linear(1000, 750)\n",
    "        \n",
    "    def forward(self, i):\n",
    "        x, _ = self.lstm(i)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a5d7ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 750])\n"
     ]
    }
   ],
   "source": [
    "net_lstm = LSTM()\n",
    "out = net_lstm(features)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "b56363f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class videocap(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(videocap, self).__init__()\n",
    "        self.layer1 = CNN()\n",
    "        self.layer2 = LSTM()\n",
    "    def forward(self, i):\n",
    "        conv1 = self.layer1(i)\n",
    "        pool1 = F.max_pool1d(conv1,1)\n",
    "        out = self.layer2(pool1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "75e218c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 750])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = videocap()\n",
    "x = torch.rand(32,1,3,256,256)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f149e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "bd712c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderLSTM(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (embedding): Embedding(829, 300)\n",
      "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "    super(EncoderLSTM, self).__init__()\n",
    "\n",
    "    # Size of the one hot vectors that will be the input to the encoder\n",
    "    self.input_size = input_size\n",
    "\n",
    "    # Output size of the word embedding NN\n",
    "    self.embedding_size = embedding_size\n",
    "\n",
    "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    # Number of layers in the lstm\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # Regularization parameter\n",
    "    self.dropout = nn.Dropout(p)\n",
    "    self.tag = True\n",
    "\n",
    "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
    "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
    "    \n",
    "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
    "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
    "\n",
    "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
    "  def forward(self, x):\n",
    "\n",
    "    # Shape -----------> (26, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "    \n",
    "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
    "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
    "    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
    "\n",
    "    return hidden_state, cell_state\n",
    "\n",
    "input_size_encoder = len(trainwords)\n",
    "encoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "encoder_dropout = float(0.5)\n",
    "\n",
    "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
    "                           hidden_size, num_layers, encoder_dropout).to(device)\n",
    "print(encoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "398bf001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderLSTM(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (embedding): Embedding(396, 300)\n",
      "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "  (fc): Linear(in_features=1024, out_features=396, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
    "    super(DecoderLSTM, self).__init__()\n",
    "\n",
    "    # Size of the one hot vectors that will be the input to the encoder\n",
    "    self.input_size = input_size\n",
    "\n",
    "    # Output size of the word embedding NN\n",
    "    self.embedding_size = embedding_size\n",
    "\n",
    "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    # Number of layers in the lstm\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
    "    self.output_size = output_size\n",
    "\n",
    "    # Regularization parameter\n",
    "    self.dropout = nn.Dropout(p)\n",
    "    self.tag = True\n",
    "\n",
    "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
    "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
    "\n",
    "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
    "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
    "\n",
    "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
    "    self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "  # Shape of x (32) [batch_size]\n",
    "  def forward(self, x, hidden_state, cell_state):\n",
    "\n",
    "    # Shape of x (1, 32) [1, batch_size]\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "\n",
    "    # Shape --> outputs (1, 32, 1024) [1, batch_size , hidden_size]\n",
    "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n",
    "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
    "\n",
    "    # Shape --> predictions (1, 32, 4556) [ 1, batch_size , output_size]\n",
    "    predictions = self.fc(outputs)\n",
    "\n",
    "    # Shape --> predictions (32, 4556) [batch_size , output_size]\n",
    "    predictions = predictions.squeeze(0)\n",
    "\n",
    "    return predictions, hidden_state, cell_state\n",
    "\n",
    "input_size_decoder = len(testwords)\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "decoder_dropout = float(0.5)\n",
    "output_size = len(testwords)\n",
    "\n",
    "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
    "                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
    "print(decoder_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ae9fb5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (Encoder_LSTM): EncoderLSTM(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (embedding): Embedding(829, 300)\n",
      "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "  )\n",
      "  (Decoder_LSTM): DecoderLSTM(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (embedding): Embedding(396, 300)\n",
      "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "    (fc): Linear(in_features=1024, out_features=396, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
    "    super(Seq2Seq, self).__init__()\n",
    "    self.Encoder_LSTM = Encoder_LSTM\n",
    "    self.Decoder_LSTM = Decoder_LSTM\n",
    "\n",
    "  def forward(self, source, target, tfr=0.5):\n",
    "    # Shape - Source : (10, 32) [(Sentence length German + some padding), Number of Sentences]\n",
    "    batch_size = source.shape[1]\n",
    "\n",
    "    # Shape - Source : (14, 32) [(Sentence length English + some padding), Number of Sentences]\n",
    "    target_len = target.shape[0]\n",
    "    target_vocab_size = len(english.vocab)\n",
    "    \n",
    "    # Shape --> outputs (14, 32, 5766) \n",
    "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "    # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
    "    hidden_state_encoder, cell_state_encoder = self.Encoder_LSTM(source)\n",
    "\n",
    "    # Shape of x (32 elements)\n",
    "    x = target[0] # Trigger token <SOS>\n",
    "\n",
    "    for i in range(1, target_len):\n",
    "      # Shape --> output (32, 5766) \n",
    "      output, hidden_state_decoder, cell_state_decoder = self.Decoder_LSTM(x, hidden_state_encoder, cell_state_encoder)\n",
    "      outputs[i] = output\n",
    "      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
    "      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
    "\n",
    "    # Shape --> outputs (14, 32, 5766) \n",
    "    return outputs\n",
    "Model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
    "print(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "79616ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1 of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/34 [00:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [10, 3, 5, 5], expected input[96, 32, 256, 256] to have 3 channels, but got 32 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [337], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m vid \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# input image\u001b[39;00m\n\u001b[0;32m      7\u001b[0m labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;66;03m# input boxes\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# output\u001b[39;00m\n\u001b[0;32m      9\u001b[0m label, box \u001b[38;5;241m=\u001b[39m out \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# define the loss function\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [329], line 7\u001b[0m, in \u001b[0;36mvideocap.forward\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[1;32m----> 7\u001b[0m     conv1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     pool1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool1d(conv1,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(pool1)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [325], line 12\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m], i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [10, 3, 5, 5], expected input[96, 32, 256, 256] to have 3 channels, but got 32 channels instead"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch{epoch +1} of {epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    for bi, data in tqdm.tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "        vid = data[0] # input image\n",
    "        labels = data[1].to(device).float() # input boxes\n",
    "        out = model(vid.to(device))  # output\n",
    "        label, box = out \n",
    "        # define the loss function\n",
    "        loss  = torch.sqrt(loss_1(box, boxes))*0.01 + loss_2(label.squeeze(0), labels) \n",
    "        # save all loss numbers by steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf91c4",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4cb1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713962ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= list(train_set['label'])[0].split()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e0e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label =[]\n",
    "for i in x:\n",
    "    label.append(wv[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7b90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten = tf.convert_to_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217b3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb37bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea626f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16083164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405743f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "model.train([[\"pilot use sun glasses\"]], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.wv['computer']\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d417789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2vdf(df):\n",
    "    w2v_df = pd.DataFrame(train_set['label']).values.tolist()\n",
    "    for i in range(len(w2v_df)):\n",
    "        w2v_df[i] = w2v_df[i][0].split(\" \")\n",
    "    return w2v_df\n",
    "\n",
    "def train_w2v(w2v_df):\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    w2v_model = Word2Vec(min_count=4,\n",
    "                         window=4,\n",
    "                         size=300, \n",
    "                         alpha=0.03, \n",
    "                         min_alpha=0.0007, \n",
    "                         sg = 1,\n",
    "                         workers=cores-1)\n",
    "    \n",
    "    w2v_model.build_vocab(w2v_df, progress_per=10000)\n",
    "    w2v_model.train(w2v_df, total_examples=w2v_model.corpus_count, epochs=100, report_delay=1)\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1328c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model[\"great\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "captionlist =list(train_set['label'])\n",
    "captionlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d81fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.wv['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_df = get_w2vdf(df)\n",
    "w2v_model = train_w2v(w2v_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3ede3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbefae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "with open('', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bf2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchtext.vocab.Vocab(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf3d39a",
   "metadata": {},
   "source": [
    "## Attention LSTM Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(torch.nn.Module):\n",
    "    def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "        super(AttentionModel, self).__init__()\n",
    "\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.word_embeddings.weights = nn.Parameter(weights, requires_grad=False)\n",
    "        self.lstm = nn.LSTM(embedding_length, hidden_size)\n",
    "        self.label = nn.Linear(hidden_size, output_size)\n",
    "        #self.attn_fc_layer = nn.Linear()\n",
    "\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "\n",
    "\n",
    "        hidden = final_state.squeeze(0)\n",
    "        attn_weights = torch.bmm(lstm_output, hidden.unsqueeze(2)).squeeze(2)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return new_hidden_state\n",
    "\n",
    "    def forward(self, input_sentences, batch_size=None):\n",
    "\n",
    "        input = self.word_embeddings(input_sentences)\n",
    "        input = input.permute(1, 0, 2)\n",
    "        if batch_size is None:\n",
    "            h_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda())\n",
    "            c_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda())\n",
    "        else:\n",
    "            h_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "            c_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0)) # final_hidden_state.size() = (1, batch_size, hidden_size) \n",
    "        output = output.permute(1, 0, 2) # output.size() = (batch_size, num_seq, hidden_size)\n",
    "\n",
    "        attn_output = self.attention_net(output, final_hidden_state)\n",
    "        logits = self.label(attn_output)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e95412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Decoder\n",
    "####################\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, use_glove, use_bert):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.encoder_dim = 2048\n",
    "        self.attention_dim = 512\n",
    "        self.use_bert = use_bert\n",
    "\n",
    "        if use_glove:\n",
    "            self.embed_dim = 300\n",
    "        elif use_bert:\n",
    "            self.embed_dim = 768\n",
    "        else:\n",
    "            self.embed_dim = 512\n",
    "\n",
    "        self.decoder_dim = 512\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = 0.5\n",
    "        \n",
    "        # soft attention\n",
    "        self.enc_att = nn.Linear(2048, 512)\n",
    "        self.dec_att = nn.Linear(512, 512)\n",
    "        self.att = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # decoder layers\n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "        self.decode_step = nn.LSTMCell(self.embed_dim + self.encoder_dim, self.decoder_dim, bias=True)\n",
    "        self.h_lin = nn.Linear(self.encoder_dim, self.decoder_dim)\n",
    "        self.c_lin = nn.Linear(self.encoder_dim, self.decoder_dim)\n",
    "        self.f_beta = nn.Linear(self.decoder_dim, self.encoder_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc = nn.Linear(self.decoder_dim, self.vocab_size)\n",
    "\n",
    "        # init variables\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "        if not use_bert:\n",
    "            self.embedding = nn.Embedding(vocab_size, self.embed_dim)\n",
    "            self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "            # load Glove embeddings\n",
    "            if use_glove:\n",
    "                self.embedding.weight = nn.Parameter(glove_vectors)\n",
    "\n",
    "            # always fine-tune embeddings (even with GloVe)\n",
    "            for p in self.embedding.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "    def forward(self, encoder_out, encoded_captions, caption_lengths):    \n",
    "        batch_size = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size = self.vocab_size\n",
    "        dec_len = [x-1 for x in caption_lengths]\n",
    "        max_dec_len = max(dec_len)\n",
    "\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)\n",
    "        num_pixels = encoder_out.size(1)\n",
    "\n",
    "        # load bert or regular embeddings\n",
    "        if not self.use_bert:\n",
    "            embeddings = self.embedding(encoded_captions)\n",
    "        elif self.use_bert:\n",
    "            embeddings = []\n",
    "            for cap_idx in  encoded_captions:\n",
    "                \n",
    "                # padd caption to correct size\n",
    "                while len(cap_idx) < max_dec_len:\n",
    "                    cap_idx.append(PAD)\n",
    "                    \n",
    "                cap = ' '.join([vocab.idx2word[word_idx.item()] for word_idx in cap_idx])\n",
    "                cap = u'[CLS] '+cap\n",
    "                \n",
    "                tokenized_cap = tokenizer.tokenize(cap)                \n",
    "                indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_cap)\n",
    "                tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    encoded_layers, _ = BertModel(tokens_tensor)\n",
    "\n",
    "                bert_embedding = encoded_layers[11].squeeze(0)\n",
    "                \n",
    "                split_cap = cap.split()\n",
    "                tokens_embedding = []\n",
    "                j = 0\n",
    "\n",
    "                for full_token in split_cap:\n",
    "                    curr_token = ''\n",
    "                    x = 0\n",
    "                    for i,_ in enumerate(tokenized_cap[1:]): # disregard CLS\n",
    "                        token = tokenized_cap[i+j]\n",
    "                        piece_embedding = bert_embedding[i+j]\n",
    "                        \n",
    "                        # full token\n",
    "                        if token == full_token and curr_token == '' :\n",
    "                            tokens_embedding.append(piece_embedding)\n",
    "                            j += 1\n",
    "                            break\n",
    "                        else: # partial token\n",
    "                            x += 1\n",
    "                            \n",
    "                            if curr_token == '':\n",
    "                                tokens_embedding.append(piece_embedding)\n",
    "                                curr_token += token.replace('#', '')\n",
    "                            else:\n",
    "                                tokens_embedding[-1] = torch.add(tokens_embedding[-1], piece_embedding)\n",
    "                                curr_token += token.replace('#', '')\n",
    "                                \n",
    "                                if curr_token == full_token: # end of partial\n",
    "                                    j += x\n",
    "                                    break                            \n",
    "\n",
    "                cap_embedding = torch.stack(tokens_embedding)\n",
    "                embeddings.append(cap_embedding)\n",
    "  \n",
    "            embeddings = torch.stack(embeddings)\n",
    "\n",
    "        # init hidden state\n",
    "        avg_enc_out = encoder_out.mean(dim=1)\n",
    "        h = self.h_lin(avg_enc_out)\n",
    "        c = self.c_lin(avg_enc_out)\n",
    "\n",
    "        predictions = torch.zeros(batch_size, max_dec_len, vocab_size).to(device)\n",
    "        alphas = torch.zeros(batch_size, max_dec_len, num_pixels).to(device)\n",
    "\n",
    "        for t in range(max(dec_len)):\n",
    "            batch_size_t = sum([l > t for l in dec_len ])\n",
    "            \n",
    "            # soft-attention\n",
    "            enc_att = self.enc_att(encoder_out[:batch_size_t])\n",
    "            dec_att = self.dec_att(h[:batch_size_t])\n",
    "            att = self.att(self.relu(enc_att + dec_att.unsqueeze(1))).squeeze(2)\n",
    "            alpha = self.softmax(att)\n",
    "            attention_weighted_encoding = (encoder_out[:batch_size_t] * alpha.unsqueeze(2)).sum(dim=1)\n",
    "        \n",
    "            gate = self.sigmoid(self.f_beta(h[:batch_size_t]))\n",
    "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
    "            \n",
    "            batch_embeds = embeddings[:batch_size_t, t, :]            \n",
    "            cat_val = torch.cat([batch_embeds.double(), attention_weighted_encoding.double()], dim=1)\n",
    "            \n",
    "            h, c = self.decode_step(cat_val.float(),(h[:batch_size_t].float(), c[:batch_size_t].float()))\n",
    "            preds = self.fc(self.dropout(h))\n",
    "            predictions[:batch_size_t, t, :] = preds\n",
    "            alphas[:batch_size_t, t, :] = alpha\n",
    "            \n",
    "        # preds, sorted capts, dec lens, attention wieghts\n",
    "        return predictions, encoded_captions, dec_len, alphas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdc9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d78fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75985ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = []\n",
    "# for i in range(len(traindataset)):\n",
    "#     s = traindataset[i][0].shape\n",
    "#     if s not in k:\n",
    "#         k.append(s)\n",
    "#         print(s)\n",
    "#     else:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "#         self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "#         self.conv3 = nn.Conv2d(20, 30, 5)\n",
    "        \n",
    "#     def forward(self, i):\n",
    "#         x = i.view(-1, i.shape[2], i.shape[3], i.shape[4])\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         x = nn.AvgPool2d(4)(x)\n",
    "#         x = x.view(i.shape[0], i.shape[1], -1)\n",
    "#         return x\n",
    "    \n",
    "# class LSTM(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LSTM, self).__init__()\n",
    "#         self.lstm = nn.LSTM(750, 100)\n",
    "#         self.fc = nn.Linear(100*50, 2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x, _ = self.lstm(x)\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "#         x = self.fc(x)\n",
    "#         return x    \n",
    "    \n",
    "# net_cnn = CNN()\n",
    "# net_lstm = LSTM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75550a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = net_cnn(x)\n",
    "# out = net_lstm(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d246c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True).to(device)\n",
    "# model.blocks[5].proj = nn.Linear(2048, 2).to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4952a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "side_size = 256\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "crop_size = 256\n",
    "num_frames = 32\n",
    "sampling_rate = 2\n",
    "frames_per_second = 30\n",
    "alpha = 4\n",
    "\n",
    "class PackPathway(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Transform for converting video frames as a list of tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, frames: torch.Tensor):\n",
    "        fast_pathway = frames\n",
    "        # Perform temporal sampling from the fast pathway.\n",
    "        slow_pathway = torch.index_select(\n",
    "            frames,\n",
    "            1,\n",
    "            torch.linspace(\n",
    "                0, frames.shape[1] - 1, frames.shape[1] // alpha\n",
    "            ).long(),\n",
    "        )\n",
    "        frame_list = [slow_pathway, fast_pathway]\n",
    "        return frame_list\n",
    "\n",
    "transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "#             NormalizeVideo(mean, std),\n",
    "            ShortSideScale(\n",
    "                size=side_size\n",
    "            ),\n",
    "            CenterCrop(crop_size),\n",
    "            PackPathway()\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The duration of the input clip is also specific to the model.\n",
    "clip_duration = (num_frames * sampling_rate)/frames_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f56b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = testpath[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sec = 0\n",
    "end_sec = start_sec + clip_duration\n",
    "\n",
    "# Initialize an EncodedVideo helper class\n",
    "video = EncodedVideo.from_path(video_path)\n",
    "\n",
    "# Load the desired clip\n",
    "video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
    "\n",
    "# Apply a transform to normalize the video input\n",
    "video_data = transform(video_data)\n",
    "\n",
    "# Move the inputs to the desired device\n",
    "inputs = video_data[\"video\"]\n",
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df68dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [i.to(device)[None, ...] for i in inputs]\n",
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804688f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db515da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted classes\n",
    "post_act = torch.nn.Softmax(dim=1)\n",
    "preds = post_act(preds)\n",
    "pred_classes = preds.topk(k=5).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22883201",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)# Initializing the look-up table.\n",
    "        self.word_embeddings.weight = nn.Parameter(weights, requires_grad=False) # Assigning the look-up table to the pre-trained GloVe word embedding.\n",
    "        self.lstm = nn.LSTM(embedding_length, hidden_size)\n",
    "        self.label = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_sentence, batch_size=None):\n",
    "        input = self.word_embeddings(input_sentence) # embedded input of shape = (batch_size, num_sequences,  embedding_length)\n",
    "        input = input.permute(1, 0, 2) # input.size() = (num_sequences, batch_size, embedding_length)\n",
    "        if batch_size is None:\n",
    "            h_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) # Initial hidden state of the LSTM\n",
    "            c_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) # Initial cell state of the LSTM\n",
    "        else:\n",
    "            h_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "            c_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0))\n",
    "        final_output = self.label(final_hidden_state[-1]) # final_hidden_state.size() = (1, batch_size, hidden_size) & final_output.size() = (batch_size, output_size)\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee611f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49338ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e438ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c25162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(torch.nn.Module):\n",
    "    def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "        super(AttentionModel, self).__init__()\n",
    "\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.word_embeddings.weights = nn.Parameter(weights, requires_grad=False)\n",
    "        self.lstm = nn.LSTM(embedding_length, hidden_size)\n",
    "        self.label = nn.Linear(hidden_size, output_size)\n",
    "        #self.attn_fc_layer = nn.Linear()\n",
    "\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "\n",
    "\n",
    "        hidden = final_state.squeeze(0)\n",
    "        attn_weights = torch.bmm(lstm_output, hidden.unsqueeze(2)).squeeze(2)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return new_hidden_state\n",
    "\n",
    "    def forward(self, input_sentences, batch_size=None):\n",
    "\n",
    "        input = self.word_embeddings(input_sentences)\n",
    "        input = input.permute(1, 0, 2)\n",
    "        if batch_size is None:\n",
    "            h_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda())\n",
    "            c_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda())\n",
    "        else:\n",
    "            h_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "            c_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
    "\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0)) # final_hidden_state.size() = (1, batch_size, hidden_size) \n",
    "        output = output.permute(1, 0, 2) # output.size() = (batch_size, num_seq, hidden_size)\n",
    "\n",
    "        attn_output = self.attention_net(output, final_hidden_state)\n",
    "        logits = self.label(attn_output)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e45923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffeaeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be38e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c62f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_set)}')\n",
    "print(f'Number of testing examples: {len(valid_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb273541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import spacy\n",
    "# from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "import torchtext.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field()\n",
    "LABELS = data.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_set)\n",
    "LABELS.build_vocab(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the predicted classes to the label names\n",
    "pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes[0]]\n",
    "print(\"Predicted labels: %s\" % \", \".join(pred_class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e98b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9a1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100aa1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    for bi, data in tqdm.tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "        \n",
    "        inputs =  data[0].to(device)\n",
    "#         labels =  data[1].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "# #         with torch.set_grad_enabled:\n",
    "        outputs = model(inputs)\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         print(type(preds))\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a8112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265997ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a086baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f06bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d56d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "516db624",
   "metadata": {},
   "source": [
    "# Video Captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129898b5",
   "metadata": {},
   "source": [
    "We try video caption models and see the result in different words performance\\\n",
    "noun, adjective, adverb, article, preposition, verb, pronoun, conjunction.\\\n",
    "model\\\n",
    "LSTM-YT, S2VT, H-RNN, DenseCap-event\\\n",
    "\n",
    "To evaluate the generated results, we first employ four different\n",
    "traditional metrics: Bleu (B) [26], METEOR (M) [20], CIDEr-D\n",
    "(C) [35], SPICE (S) [1] and Rouge-L (R) [2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b35c67",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
